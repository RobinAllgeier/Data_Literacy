{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c15ff28",
   "metadata": {},
   "source": [
    "# 03 – Data Cleaning (Library Borrowings)\n",
    "\n",
    "**Purpose:** Create an analysis-ready dataset by applying a small set of clearly defined cleaning rules based on the sanity-check findings.\n",
    "\n",
    "This notebook:\n",
    "- loads the merged dataset,\n",
    "- parses key columns (timestamps, numeric fields),\n",
    "- removes records with critical inconsistencies\n",
    "- saves a cleaned dataset for EDA.\n",
    "\n",
    "**Not included:**\n",
    "- no exploratory analysis or visualizations beyond basic before/after counts\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4382866d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T13:59:51.555323940Z",
     "start_time": "2026-01-19T13:59:51.200224722Z"
    }
   },
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import setup_pandas, setup_plotting\n",
    "\n",
    "\n",
    "# --- global notebook setup (pandas + tueplots/matplotlib style) ---\n",
    "setup_pandas()\n",
    "setup_plotting()\n",
    "\n",
    "\n",
    "# --- project paths ---\n",
    "PROCESSED_DATA_PATH = Path('../dat/processed')\n",
    "RAW_DATA_PATH = Path('../dat/raw')\n",
    "\n",
    "DATA_FILE = PROCESSED_DATA_PATH / \"borrowings_2019_2025.csv\"\n",
    "CLEANED_FILE = PROCESSED_DATA_PATH / \"borrowings_2019_2025_cleaned.csv\"\n",
    "\n",
    "CLOSED_DAYS_FILE = RAW_DATA_PATH / \"closed_days_2019_2025.csv\""
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "9349caeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:00:04.017996529Z",
     "start_time": "2026-01-19T13:59:51.623462275Z"
    }
   },
   "source": [
    "# --- load data ---\n",
    "borrowings = pd.read_csv(\n",
    "    DATA_FILE,\n",
    "    sep=\";\",\n",
    "    quotechar='\"',\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "closed_days = pd.read_csv(\n",
    "    CLOSED_DAYS_FILE,\n",
    "    sep=\";\",\n",
    "    quotechar='\"',\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"Loaded shape:\", borrowings.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (2407610, 17)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "b184df61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:00:07.519440383Z",
     "start_time": "2026-01-19T14:00:04.027516058Z"
    }
   },
   "source": [
    "# --- preprocess relevant columns ---\n",
    "\n",
    "# column names\n",
    "ISSUE_COL = \"Ausleihdatum/Uhrzeit\"\n",
    "RETURN_COL = \"Rückgabedatum/Uhrzeit\"\n",
    "\n",
    "DURATION_COL = \"Leihdauer\"\n",
    "EXT_COL = \"Anzahl_Verlängerungen\"\n",
    "LATE_FLAG_COL = \"Verspätet\"\n",
    "LATE_DAYS_COL = \"Tage_zu_spät\"\n",
    "\n",
    "ID_COL = \"issue_id\"\n",
    "USER_CATEGORY_COL = \"Benutzerkategorie\"\n",
    "USER_COL = \"Benutzer-Systemnummer\"\n",
    "BARCODE_COL = \"Barcode\"\n",
    "\n",
    "MEDIA_TYPE_COL = \"Medientyp\"\n",
    "CCODE_COL = \"Sammlungszeichen/CCODE\"\n",
    "\n",
    "# timestamps\n",
    "for c in [ISSUE_COL, RETURN_COL]:\n",
    "    if c in borrowings.columns:\n",
    "        borrowings[c] = pd.to_datetime(borrowings[c], errors=\"coerce\")\n",
    "\n",
    "# numeric columns\n",
    "for c in [DURATION_COL, EXT_COL, LATE_DAYS_COL]:\n",
    "    if c in borrowings.columns:\n",
    "        borrowings[c] = pd.to_numeric(borrowings[c], errors=\"coerce\")\n",
    "\n",
    "# normalize late flag to boolean (Ja/Nein -> True/False); keep unknown as <NA>\n",
    "if LATE_FLAG_COL in borrowings.columns:\n",
    "    v = borrowings[LATE_FLAG_COL].astype(str).str.strip().str.lower()\n",
    "    borrowings[\"late_bool\"] = pd.Series(np.where(v == \"ja\", True, np.where(v == \"nein\", False, pd.NA)), dtype=\"boolean\")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "828ea1d9",
   "metadata": {},
   "source": [
    "## Cleaning rules\n",
    "\n",
    "We remove records that violate fundamental consistency constraints of borrowing transactions:\n",
    "\n",
    "1. Missing return and leihdauer timestamp\n",
    "2. Leihdauer exceeds the max durration given by the 28 days and a max of 6 extensions.\n",
    "3. Non-representative users are removed\n",
    "4. Removal of media types (optional)\n",
    "5. Removal of ccodes (optional)\n",
    "\n",
    "**ATTENTION: So far, only rules for the loan period and return have been formulated.\n",
    "Further rules should be defined for further analyses on other columns!**\n",
    "\n",
    "No other filtering is applied at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679849d",
   "metadata": {},
   "source": [
    "### 1. Missing return timestamp and leihdauer timestamp\n",
    "\n",
    "Records without a return timestamp, corresponding to items not yet returned at the time of data extraction, were excluded from further analysis."
   ]
  },
  {
   "cell_type": "code",
   "id": "cd224bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:00:10.217785682Z",
     "start_time": "2026-01-19T14:00:07.524727002Z"
    }
   },
   "source": [
    "# --- heck assumption: missing return timestamp ⇔ missing duration ---\n",
    "mask_return_missing = borrowings[RETURN_COL].isna()\n",
    "mask_duration_missing = borrowings[DURATION_COL].isna()\n",
    "\n",
    "check_table = pd.crosstab(\n",
    "    mask_return_missing,\n",
    "    mask_duration_missing,\n",
    "    rownames=[\"return_missing\"],\n",
    "    colnames=[\"duration_missing\"]\n",
    ")\n",
    "\n",
    "display(check_table)\n",
    "\n",
    "# verify assumption\n",
    "if check_table.loc[True, False] == 0:\n",
    "    print(\"Assumption holds: whenever return timestamp is missing, duration is also missing.\")\n",
    "else:\n",
    "    print(\"WARNING: There are cases with missing return timestamp but present duration.\")\n",
    "\n",
    "# remove not-yet-returned items (missing return timestamp)\n",
    "before_n = len(borrowings)\n",
    "borrowings = borrowings.loc[~mask_return_missing].copy()\n",
    "after_n = len(borrowings)\n",
    "\n",
    "print(f\"Removed {before_n - after_n} rows with missing return timestamp.\")\n",
    "print(\"Remaining rows:\", after_n)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_missing    False  True \n",
       "return_missing                  \n",
       "False             2358824      0\n",
       "True                    0  48786"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>duration_missing</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_missing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2358824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0</td>\n",
       "      <td>48786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumption holds: whenever return timestamp is missing, duration is also missing.\n",
      "Removed 48786 rows with missing return timestamp.\n",
      "Remaining rows: 2358824\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "e1131ae2",
   "metadata": {},
   "source": [
    "### 2. removal of loans exceeding the maximum allowed duration\n",
    "\n",
    "Loan durations are recalculated in terms of **library open days**, accounting for weekly closing days (Sunday and Monday) and official closure days.\n",
    "Based on the borrowing rules, a maximum loan duration is derived as 28 days plus allowed extensions (capped at six).\n",
    "\n",
    "Loans whose open-day duration exceeds this rule-based maximum are flagged as implausible and removed.\n",
    "This step ensures that the dataset reflects valid borrowing behavior and excludes records likely caused by data errors or exceptional administrative cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6d8c19d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:00:12.172993595Z",
     "start_time": "2026-01-19T14:00:10.221243123Z"
    }
   },
   "source": [
    "# --- remove loans exceeding max loan duration ---\n",
    "closed_days[\"schliesstag\"] = pd.to_datetime(closed_days[\"schliesstag\"], dayfirst=True, errors=\"coerce\")\n",
    "holidays = (\n",
    "    closed_days[\"schliesstag\"]\n",
    "    .dropna()\n",
    "    .dt.normalize()\n",
    "    .drop_duplicates()\n",
    "    .values.astype(\"datetime64[D]\")\n",
    ")\n",
    "\n",
    "start = borrowings[ISSUE_COL].dt.normalize().values.astype(\"datetime64[D]\")\n",
    "end = borrowings[RETURN_COL].dt.normalize().values.astype(\"datetime64[D]\")\n",
    "\n",
    "# library open days: Tue–Sat (closed every Sunday+Monday) => Mon..Sun: 0,1,1,1,1,1,0\n",
    "weekmask = \"0111110\"\n",
    "\n",
    "open_days = np.full(len(borrowings), np.nan, dtype=\"float64\")\n",
    "valid = (~np.isnan(start) & ~np.isnan(end)) & (end >= start)\n",
    "\n",
    "open_days[valid] = np.busday_count(\n",
    "    start[valid],\n",
    "    end[valid],     # counts in [start, end)\n",
    "    weekmask=weekmask,\n",
    "    holidays=holidays\n",
    ").astype(\"float64\")\n",
    "\n",
    "borrowings[\"open_days_leihdauer\"] = open_days\n",
    "\n",
    "#  allowed max = 28 days * (1 + extensions), with extensions capped at 6\n",
    "ext = pd.to_numeric(borrowings[EXT_COL], errors=\"coerce\").fillna(0).clip(lower=0, upper=6)\n",
    "borrowings[\"max_allowed_open_days\"] = 28 * (1 + ext)\n",
    "\n",
    "borrowings[\"weird_loan\"] = (borrowings[\"open_days_leihdauer\"] > borrowings[\"max_allowed_open_days\"]).fillna(False)\n",
    "\n",
    "borrowings.loc[borrowings[\"weird_loan\"]].sort_values(\n",
    "    \"open_days_leihdauer\", ascending=False\n",
    ")[\n",
    "    [ISSUE_COL, DURATION_COL, \"open_days_leihdauer\", EXT_COL, \"max_allowed_open_days\", \"weird_loan\"]\n",
    "].head(10)\n",
    "\n",
    "\n",
    "# removing loans exceeding allowed open days\n",
    "before_n = len(borrowings)\n",
    "borrowings = borrowings.loc[~borrowings[\"weird_loan\"]].copy()\n",
    "\n",
    "after_n = len(borrowings)\n",
    "removed_n = before_n - after_n\n",
    "\n",
    "print(f\"Removed {removed_n} rows with Leihdauer exceeding max loan duration.\")\n",
    "print(\"Remaining rows:\", after_n)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 8625 rows with Leihdauer exceeding max loan duration.\n",
      "Remaining rows: 2350199\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "0f6821d9",
   "metadata": {},
   "source": [
    "### 3. removal of system users\n",
    "\n",
    "System and administrative accounts (`SYS`, `MDA`) are excluded, as they do not represent regular user behavior.\n",
    "Removing these records prevents technical or administrative activity from biasing the analysis."
   ]
  },
  {
   "cell_type": "code",
   "id": "1e224545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:00:13.089527355Z",
     "start_time": "2026-01-19T14:00:12.178822194Z"
    }
   },
   "source": [
    "# --- remove non-representative users (system / administrative accounts) ---\n",
    "before_n = len(borrowings)\n",
    "\n",
    "borrowings = borrowings.loc[\n",
    "    ~borrowings[USER_CATEGORY_COL].isin([\"SYS\", \"MDA\"])\n",
    "].copy()\n",
    "\n",
    "after_n = len(borrowings)\n",
    "\n",
    "print(f\"Removed {before_n - after_n} rows from system/administrative users (SYS, MDA).\")\n",
    "print(\"Remaining rows:\", after_n)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 37127 rows from system/administrative users (SYS, MDA).\n",
      "Remaining rows: 2313072\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Removal of media types (optional)\n",
    "\n",
    "For some analyses, it can be useful to remove rarely used media types. You can also configure how media types are classified into book and non-book categories here. By default, no media types are removed. Update the `BOOK_TYPES_ONLY` flag or the variables `UNINTERESTING_MEDIA_TYPES` and `MIN_BORROWINGS_PER_MEDIA_TYPE` to change this behavior."
   ],
   "id": "93035061589fd83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:00:14.362300566Z",
     "start_time": "2026-01-19T14:00:13.092829057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BOOK_TYPES_ONLY = False\n",
    "UNINTERESTING_MEDIA_TYPES = [\n",
    "    #\"Sonstiges\" # mixed media type with unknown contents\n",
    "]\n",
    "MIN_BORROWINGS_PER_MEDIA_TYPE = 0\n",
    "\n",
    "book_categories = [\n",
    "    \"Sachbuch\",\n",
    "    \"Belletristik\",\n",
    "    \"Fremdsprachige Belletristik\",\n",
    "    \"Kinder u. Jugendbuch\",\n",
    "    \"Comic\",\n",
    "    \"Zeitschriften\",\n",
    "]\n",
    "\n",
    "# only book types\n",
    "if BOOK_TYPES_ONLY:\n",
    "    borrowings = borrowings[borrowings[MEDIA_TYPE_COL].isin(book_categories)].reset_index(drop=True)\n",
    "\n",
    "# apply min borrowings filter\n",
    "counts = borrowings[MEDIA_TYPE_COL].value_counts()\n",
    "keep_types = counts.index[counts >= MIN_BORROWINGS_PER_MEDIA_TYPE]\n",
    "borrowings = borrowings[borrowings[MEDIA_TYPE_COL].isin(keep_types)].reset_index(drop=True)\n",
    "\n",
    "# remove uninteresting types\n",
    "borrowings = borrowings[~borrowings[MEDIA_TYPE_COL].isin(UNINTERESTING_MEDIA_TYPES)].reset_index(drop=True)\n"
   ],
   "id": "e6eab0a029a87054",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Removal of CCodes (optional)\n",
    "\n",
    "For some analyses, it can be useful to remove rarely used CCodes. By default, no ccodes are removed. Update the variable `MIN_BORROWINGS_PER_CCODE` to change this behavior."
   ],
   "id": "e716f3bf4925a724"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:00:15.092467780Z",
     "start_time": "2026-01-19T14:00:14.364308919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MIN_BORROWINGS_PER_CCODE = 100\n",
    "\n",
    "# apply min borrowings filter\n",
    "counts = borrowings[CCODE_COL].value_counts()\n",
    "keep_types = counts.index[counts >= MIN_BORROWINGS_PER_CCODE]\n",
    "borrowings = borrowings[borrowings[CCODE_COL].isin(keep_types)].reset_index(drop=True)"
   ],
   "id": "a0a5021a71589cae",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "fc9b1d9f",
   "metadata": {},
   "source": [
    "## Save cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "5da81655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:00:33.481423295Z",
     "start_time": "2026-01-19T14:00:15.106841593Z"
    }
   },
   "source": [
    "borrowings.to_csv(CLEANED_FILE, index=False, sep=\";\", quotechar='\"', encoding=\"utf-8\")\n",
    "print(\"Saved cleaned dataset to:\", CLEANED_FILE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset to: ../dat/processed/borrowings_2019_2025_cleaned.csv\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "12c77764",
   "metadata": {},
   "source": [
    "## Cleaning summary\n",
    "\n",
    "- missing return stamp and leihdauer were removed, also loan period longer than 365 days\n",
    "- The resulting dataset is intended as the input for EDA and modeling notebooks.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
